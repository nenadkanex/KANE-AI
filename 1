=== settings.gradle.kts ===
rootProject.name = "MojAIApp"
include(":app")


=== build.gradle.kts (Project level) ===
plugins {
    id("com.android.application") version "8.3.0" apply false
    id("org.jetbrains.kotlin.android") version "1.9.23" apply false
}


=== app/build.gradle.kts ===
plugins {
    id("com.android.application")
    id("org.jetbrains.kotlin.android")
}

android {
    namespace = "com.mojai.app"
    compileSdk = 34

    defaultConfig {
        applicationId = "com.mojai.app"
        minSdk = 28
        targetSdk = 34
        versionCode = 1
        versionName = "1.0"
        
        ndk {
            abiFilters.add("arm64-v8a")
        }
        externalNativeBuild {
            cmake {
                cppFlags.add("-std=c++17")
                arguments.add("-DLLAMA_ANDROID=ON")
            }
        }
    }

    buildTypes {
        release {
            isMinifyEnabled = false
        }
    }

    compileOptions {
        sourceCompatibility = JavaVersion.VERSION_1_8
        targetCompatibility = JavaVersion.VERSION_1_8
    }

    kotlinOptions {
        jvmTarget = "1.8"
    }

    buildFeatures {
        compose = true
    }

    composeOptions {
        kotlinCompilerExtensionVersion = "1.5.8"
    }

    externalNativeBuild {
        cmake {
            path = file("src/main/cpp/CMakeLists.txt")
            version = "3.22.1"
        }
    }
}

dependencies {
    implementation("androidx.core:core-ktx:1.12.0")
    implementation("androidx.appcompat:appcompat:1.6.1")
    implementation("com.google.android.material:material:1.11.0")
    
    // Compose
    implementation("androidx.compose.ui:ui:1.6.4")
    implementation("androidx.compose.material3:material3:1.2.1")
    implementation("androidx.compose.ui:ui-tooling-preview:1.6.4")
    implementation("androidx.activity:activity-compose:1.8.2")
    
    // Lifecycle
    implementation("androidx.lifecycle:lifecycle-runtime-ktx:2.7.0")
    implementation("androidx.lifecycle:lifecycle-viewmodel-compose:2.7.0")
}


=== app/src/main/AndroidManifest.xml ===
<?xml version="1.0" encoding="utf-8"?>
<manifest xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:tools="http://schemas.android.com/tools">

    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />
    
    <application
        android:allowBackup="true"
        android:icon="@drawable/ic_launcher"
        android:label="Moj AI"
        android:theme="@style/Theme.AppCompat.Light.NoActionBar"
        tools:targetApi="34">

        <activity
            android:name=".MainActivity"
            android:exported="true"
            android:label="Moj AI">
            <intent-filter>
                <action android:name="android.intent.action.MAIN" />
                <category android:name="android.intent.category.LAUNCHER" />
            </intent-filter>
        </activity>
    </application>
</manifest>


=== app/src/main/java/com/mojai/app/LlamaBridge.kt ===
package com.mojai.app

class LlamaBridge {
    external fun loadModel(modelPath: String): Boolean
    external fun generate(prompt: String, maxTokens: Int): String
    external fun unloadModel()

    companion object {
        init {
            System.loadLibrary("llama-android")
        }
    }
}


=== app/src/main/java/com/mojai/app/MainActivity.kt ===
package com.mojai.app

import android.content.Intent
import android.net.Uri
import android.os.Bundle
import android.os.Environment
import androidx.activity.ComponentActivity
import androidx.activity.compose.setContent
import androidx.compose.foundation.layout.*
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.ui.Modifier
import androidx.compose.ui.unit.dp
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewmodel.compose.viewModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext

class MainViewModel : ViewModel() {
    private val llamaBridge = LlamaBridge()
    var isModelLoaded by mutableStateOf(false)
    var chatHistory by mutableStateOf(listOf<Pair<String, String>>())
    var isGenerating by mutableStateOf(false)

    suspend fun loadModel() {
        withContext(Dispatchers.IO) {
            val modelPath = Environment.getExternalStorageDirectory().path + 
                "/Download/Meta-Llama-3.1-8B-Instruct.Q4_0_4_8.gguf"
            isModelLoaded = llamaBridge.loadModel(modelPath)
        }
    }

    suspend fun generate(prompt: String) {
        if (!isModelLoaded || isGenerating) return
        isGenerating = true
        
        chatHistory = chatHistory + ("User" to prompt)
        
        withContext(Dispatchers.IO) {
            val response = llamaBridge.generate(prompt, 256)
            chatHistory = chatHistory + ("AI" to response)
        }
        
        isGenerating = false
    }

    fun openInChatApp(message: String, app: String) {
        val intent = Intent(Intent.ACTION_VIEW).apply {
            when (app) {
                "whatsapp" -> data = Uri.parse("https://wa.me/?text=${Uri.encode(message)}")
                "signal" -> data = Uri.parse("https://signal.me/#p/?text=${Uri.encode(message)}")
            }
        }
    }

    override fun onCleared() {
        llamaBridge.unloadModel()
        super.onCleared()
    }
}

class MainActivity : ComponentActivity() {
    @OptIn(ExperimentalMaterial3Api::class)
    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        
        setContent {
            val viewModel = viewModel<MainViewModel>()
            var userInput by remember { mutableStateOf("") }
            
            LaunchedEffect(Unit) {
                viewModel.loadModel()
            }

            MaterialTheme {
                Scaffold(
                    topBar = {
                        TopAppBar(
                            title = { Text("Moj AI - Llama 3.1 8B") }
                        )
                    }
                ) { padding ->
                    Column(
                        modifier = Modifier
                            .fillMaxSize()
                            .padding(padding)
                            .padding(16.dp)
                    ) {
                        if (!viewModel.isModelLoaded) {
                            Text("Učitavanje modela...", modifier = Modifier.padding(bottom = 16.dp))
                            LinearProgressIndicator(modifier = Modifier.fillMaxWidth())
                        }
                        
                        // Chat history
                        LazyColumn(
                            modifier = Modifier.weight(1f),
                            verticalArrangement = Arrangement.spacedBy(8.dp)
                        ) {
                            items(viewModel.chatHistory) { (sender, message) ->
                                Card {
                                    Column(modifier = Modifier.padding(12.dp)) {
                                        Text(
                                            text = sender,
                                            style = MaterialTheme.typography.labelSmall,
                                            color = MaterialTheme.colorScheme.primary
                                        )
                                        Spacer(modifier = Modifier.height(4.dp))
                                        Text(text = message)
                                    }
                                }
                            }
                        }
                        
                        // Input
                        OutlinedTextField(
                            value = userInput,
                            onValueChange = { userInput = it },
                            modifier = Modifier.fillMaxWidth(),
                            label = { Text("Unesi pitanje") },
                            enabled = viewModel.isModelLoaded && !viewModel.isGenerating
                        )
                        
                        Spacer(modifier = Modifier.height(8.dp))
                        
                        // Buttons
                        Row(
                            modifier = Modifier.fillMaxWidth(),
                            horizontalArrangement = Arrangement.SpaceEvenly
                        ) {
                            Button(
                                onClick = {
                                    viewModel.generate(userInput)
                                    userInput = ""
                                },
                                enabled = viewModel.isModelLoaded && !viewModel.isGenerating && userInput.isNotBlank()
                            ) {
                                Text(if (viewModel.isGenerating) "Generišem..." else "Pošalji")
                            }
                            
                            // Buttons to open in chat apps
                            viewModel.chatHistory.lastOrNull()?.let { (_, lastMessage) ->
                                IconButton(onClick = { viewModel.openInChatApp(lastMessage, "whatsapp") }) {
                                    Text("WA")
                                }
                                IconButton(onClick = { viewModel.openInChatApp(lastMessage, "signal") }) {
                                    Text("SG")
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}


=== app/src/main/cpp/CMakeLists.txt ===
cmake_minimum_required(VERSION 3.18)

project(llama-android)

# Download llama.cpp
include(FetchContent)
FetchContent_Declare(
    llama
    GIT_REPOSITORY https://github.com/ggerganov/llama.cpp
    GIT_TAG master
)
FetchContent_MakeAvailable(llama)

# Create wrapper library
add_library(llama-android SHARED llama-android.cpp)

target_link_libraries(llama-android 
    llama 
    ggml
    android
    log
)

target_include_directories(llama-android PRIVATE 
    ${llama_SOURCE_DIR}
)


=== app/src/main/cpp/llama-android.cpp ===
#include <jni.h>
#include <string>
#include <android/log.h>
#include "llama.h"

#define LOG_TAG "LlamaAndroid"
#define LOGI(...) __android_log_print(ANDROID_LOG_INFO, LOG_TAG, __VA_ARGS__)
#define LOGE(...) __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)

static llama_model* model = nullptr;
static llama_context* ctx = nullptr;

extern "C" JNIEXPORT jboolean JNICALL
Java_com_mojai_app_LlamaBridge_loadModel(JNIEnv *env, jobject, jstring modelPath) {
    const char *path = env->GetStringUTFChars(modelPath, nullptr);
    
    llama_model_params model_params = llama_model_default_params();
    model = llama_load_model_from_file(path, model_params);
    
    env->ReleaseStringUTFChars(modelPath, path);
    
    if (model == nullptr) {
        LOGE("Failed to load model");
        return JNI_FALSE;
    }
    
    llama_context_params ctx_params = llama_context_default_params();
    ctx_params.n_ctx = 4096;
    ctx_params.n_gpu_layers = 999;
    
    ctx = llama_new_context_with_model(model, ctx_params);
    
    if (ctx == nullptr) {
        LOGE("Failed to create context");
        llama_free_model(model);
        model = nullptr;
        return JNI_FALSE;
    }
    
    LOGI("Model loaded successfully");
    return JNI_TRUE;
}

extern "C" JNIEXPORT jstring JNICALL
Java_com_mojai_app_LlamaBridge_generate(JNIEnv *env, jobject, jstring prompt, jint max_tokens) {
    if (ctx == nullptr) {
        return env->NewStringUTF("Model not loaded");
    }
    
    const char *prompt_c = env->GetStringUTFChars(prompt, nullptr);
    std::string prompt_str(prompt_c);
    env->ReleaseStringUTFChars(prompt, prompt_c);
    
    auto tokens = llama_tokenize(ctx, prompt_str, true);
    
    if (llama_eval(ctx, tokens.data(), tokens.size(), 0, 4) != 0) {
        return env->NewStringUTF("Evaluation failed");
    }
    
    std::string response;
    
    for (int i = 0; i < max_tokens; i++) {
        llama_token new_token_id = llama_sampling_sample(ctx, nullptr, nullptr);
        
        if (llama_token_is_eog(model, new_token_id)) break;
        
        response += llama_token_to_piece(ctx, new_token_id);
        
        if (llama_eval(ctx, &new_token_id, 1, tokens.size() + i, 4) != 0) break;
    }
    
    return env->NewStringUTF(response.c_str());
}

extern "C" JNIEXPORT void JNICALL
Java_com_mojai_app_LlamaBridge_unloadModel(JNIEnv *, jobject) {
    if (ctx) {
        llama_free(ctx);
        ctx = nullptr;
    }
    if (model) {
        llama_free_model(model);
        model = nullptr;
    }
    LOGI("Model unloaded");
}


=== app/src/main/res/drawable/ic_launcher.xml ===
<vector xmlns:android="http://schemas.android.com/apk/res/android"
    android:width="48dp"
    android:height="48dp"
    android:viewportWidth="48"
    android:viewportHeight="48">
    <path
        android:fillColor="#3DDC84"
        android:pathData="M24,24m-24,0a24,24 0,1 1,48 0a24,24 0,1 1,-48 0"/>
    <path
        android:fillColor="#FFFFFF"
        android:pathData="M16,16h16v16h-16z"/>
</vector>


=== gradle/wrapper/gradle-wrapper.properties ===
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-8.4-bin.zip
networkTimeout=10000
validateDistributionUrl=true
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists


=== .github/workflows/build.yml ===
name: Build APK

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        java-version: '17'
        distribution: 'temurin'
        
    - name: Setup Android SDK
      uses: android-actions/setup-android@v2
      
    - name: Cache Gradle
      uses: actions/cache@v3
      with:
        path: |
          ~/.gradle/caches
          ~/.gradle/wrapper
        key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*') }}
        
    - name: Grant execute permission for gradlew
      run: chmod +x gradlew
      
    - name: Build APK
      run: ./gradlew assembleDebug
      
    - name: Upload APK
      uses: actions/upload-artifact@v3
      with:
        name: MojAIApp-APK
        path: app/build/outputs/apk/debug/app-debug.apk


